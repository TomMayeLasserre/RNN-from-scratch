{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a82384",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutional Neural Network (CNN)\n",
    "\n",
    "### Definition:\n",
    "\n",
    "A CNN is a specialized type of neural network for processing grid-like data, such as images. Instead of fully connected layers, CNNs use convolutional layers, pooling layers, and optionally fully connected layers. \n",
    "\n",
    "### Convolutional Layer:\n",
    "\n",
    "The convolution operation for a single filter \\( \\mathbf{W} \\) applied to an input image \\( \\mathbf{X} \\) can be expressed as:\n",
    "\\[\\mathbf{Z}(i,j) = \\sum_{m=1}^{M} \\sum_{n=1}^{N} \\mathbf{W}(m,n) \\cdot \\mathbf{X}(i+m, j+n)\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mathbf{Z}(i,j) \\) is the output of the convolution at position \\( (i, j) \\).\n",
    "- \\( \\mathbf{W}(m,n) \\) are the learnable weights (filter) of size \\( M \times N \\).\n",
    "- \\( \\mathbf{X}(i+m, j+n) \\) is the input data (image or feature map).\n",
    "\n",
    "### Activation Function:\n",
    "\n",
    "After the convolution, an activation function is applied elementwise to the output \\( \\mathbf{Z} \\), typically the ReLU function:\n",
    "\\[ \\mathbf{A}(i,j) = \\max(0, \\mathbf{Z}(i,j)) \\]\n",
    "\n",
    "### Pooling Layer:\n",
    "\n",
    "The pooling operation, often max pooling, reduces the dimensionality of the data. It can be expressed as:\n",
    "\\[\\mathbf{P}(i,j) = \\max_{m,n} \\mathbf{A}(i+m, j+n)\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\mathbf{P}(i,j) \\) is the pooled output.\n",
    "- \\( \\max_{m,n} \\) denotes taking the maximum value within a local patch (e.g., \\( 2 \times 2 \\)).\n",
    "\n",
    "### Fully Connected Layer:\n",
    "\n",
    "After several convolution and pooling layers, the data is typically flattened and fed into a fully connected layer, as in an MLP:\n",
    "\\[\\mathbf{y} = \\sigma(\\mathbf{W}^{(L)} \\mathbf{h}^{(L-1)} + \\mathbf{b}^{(L)})\\]\n",
    "\n",
    "### Backpropagation:\n",
    "\n",
    "Similar to MLPs, CNNs are trained using backpropagation. The gradients of the loss function \\( \\mathcal{L}(\\mathbf{y}, \\mathbf{t}) \\) with respect to the filter weights are computed as:\n",
    "\n",
    "\\[\f",
    "rac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}} = \\sum_{i,j} \f",
    "rac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}(i,j)} \\cdot \\mathbf{X}(i,j)\\]\n",
    "\n",
    "Where:\n",
    "- \\( \f",
    "rac{\\partial \\mathcal{L}}{\\partial \\mathbf{Z}(i,j)} \\) is the gradient of the loss with respect to the convolution output.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
